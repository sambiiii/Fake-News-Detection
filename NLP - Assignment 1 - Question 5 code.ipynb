{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sMGQXyMzPGzK",
        "outputId": "49c4bae6-2680-4754-cbdb-d52684348259"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (3.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from nltk) (1.2.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from nltk) (7.1.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.7/dist-packages (from nltk) (2022.6.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from nltk) (4.64.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install nltk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "nOBr4d31PGzM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "658bd86c-d4ce-41ea-83db-23f907087924"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import csv                               # csv reader\n",
        "from sklearn.svm import LinearSVC\n",
        "from nltk.classify import SklearnClassifier\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import precision_recall_fscore_support # to report on precision and recall\n",
        "import numpy as np\n",
        "\n",
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "import nltk\n",
        "from nltk import bigrams\n",
        "import nltk\n",
        "from nltk import trigrams"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "qoPdohdUPGzM"
      },
      "outputs": [],
      "source": [
        "def load_data(path):\n",
        "    \"\"\"Load data from a tab-separated file and append it to raw_data.\"\"\"\n",
        "    with open(path) as f:\n",
        "        reader = csv.reader(f, delimiter='\\t')\n",
        "        for line in reader:\n",
        "            if line[0] == \"Id\":  # skip header\n",
        "                continue\n",
        "            (label, text) = parse_data_line(line)\n",
        "            raw_data.append((text, label))\n",
        "\n",
        "def split_and_preprocess_data(percentage):\n",
        "    \"\"\"Split the data between train_data and test_data according to the percentage\n",
        "    and performs the preprocessing.\"\"\"\n",
        "    num_samples = len(raw_data)\n",
        "    num_training_samples = int((percentage * num_samples))\n",
        "    for (text, label) in raw_data[:num_training_samples]:\n",
        "        train_data.append((to_feature_vector(pre_process(text)),label))\n",
        "    for (text, label) in raw_data[num_training_samples:]:\n",
        "        test_data.append((to_feature_vector(pre_process(text)),label))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d7yeUVmVPGzN"
      },
      "source": [
        "# Question 1: Input and Basic preprocessing (10 marks)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "j4UQuRFyPGzN"
      },
      "outputs": [],
      "source": [
        "def convert_label(label):\n",
        "    \"\"\"Converts the multiple classes into two,\n",
        "    making it a binary distinction between fake news and real.\"\"\"\n",
        "    #return label\n",
        "    # Converting the multiclass labels to binary label\n",
        "    labels_map = {\n",
        "        'true': 'REAL',\n",
        "        'mostly-true': 'REAL',\n",
        "        'half-true': 'REAL',\n",
        "        'false': 'FAKE',\n",
        "        'barely-true': 'FAKE',\n",
        "        'pants-fire': 'FAKE'\n",
        "    }\n",
        "    return labels_map[label]\n",
        "\n",
        "\n",
        "def parse_data_line(data_line):\n",
        "    # Should return a tuple of the label as just FAKE or REAL and the statement\n",
        "    # e.g. (label, statement)\n",
        "    return (convert_label(data_line[1]), data_line[2])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F2LNz4oePGzO",
        "outputId": "76c1076a-0a75-4da7-8ee8-ba04e4d87431"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "from string import punctuation\n",
        "import nltk\n",
        "import re\n",
        "nltk.download('punkt')\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "\n",
        "# REMOVE STOP WORD\n",
        "#def pre_process(text):\n",
        "#  vectorizer = CountVectorizer(stop_words = 'english')\n",
        "#  analyze = vectorizer.build_analyzer()\n",
        "#  tokens=analyze(text)\n",
        "#  return tokens\n",
        "\n",
        "\n",
        "# # # To lemmatize the data\n",
        "#import nltk\n",
        "#nltk.download('wordnet')\n",
        "#nltk.download('omw-1.4')\n",
        "#from nltk.stem import WordNetLemmatizer\n",
        "# # # LEMMATIZING\n",
        "#wnl = WordNetLemmatizer()\n",
        "#def pre_process(text):\n",
        "#  vectorizer = CountVectorizer(stop_words = 'english')\n",
        "#  analyze = vectorizer.build_analyzer()\n",
        "#  tokens=analyze(text)\n",
        "#  tokens = [wnl.lemmatize(t) for t in tokens]\n",
        "# # #Should return a list of tokens\n",
        "#  return tokens\n",
        "\n",
        "\n",
        "#BIGRAMS\n",
        "import nltk\n",
        "from nltk import bigrams\n",
        "def pre_process(text):\n",
        "  no_symbols = re.sub(r'[^\\w]', ' ', text.lower())\n",
        "  tokens = no_symbols.split()\n",
        "  bitokens = list(bigrams(tokens))\n",
        "  return bitokens\n",
        "\n",
        "#TRIGRAMS\n",
        "#import nltk\n",
        "#from nltk import trigrams\n",
        "#def pre_process(text):\n",
        "#    #normalisation and tokenising \n",
        "#    no_symbols = re.sub(r'[^\\w]', ' ', text.lower())\n",
        "#    tokens = no_symbols.split()\n",
        "#    tritokens = list(trigrams(tokens))\n",
        "#    return tritokens\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "kXtj4A7raPeS"
      },
      "outputs": [],
      "source": [
        "#[word.lower() for word in word_tokenize(text) if word not in punctuation]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XpaTPyLzPGzO"
      },
      "source": [
        "# Question 2: Basic Feature Extraction (20 marks)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "fiI-bQxHPGzP"
      },
      "outputs": [],
      "source": [
        "global_feature_dict = {} # A global dictionary of features\n",
        "\n",
        "def to_feature_vector(tokens):\n",
        "    # Should return a dictionary containing features as keys, and weights as values\n",
        "    # DESCRIBE YOUR METHOD IN WORDS\n",
        "    result = {}\n",
        "    for token in tokens:\n",
        "        if token not in result:\n",
        "            result[token] = 0\n",
        "        result[token] += 1\n",
        "        if token not in global_feature_dict:\n",
        "            global_feature_dict[token] = 0\n",
        "        global_feature_dict[token] += 1\n",
        "    return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "Pjq9MqvXPGzP"
      },
      "outputs": [],
      "source": [
        "# TRAINING AND VALIDATING OUR CLASSIFIER\n",
        "\n",
        "def train_classifier(data):\n",
        "    print(\"Training Classifier...\")\n",
        "    pipeline =  Pipeline([('svc', LinearSVC())])\n",
        "    return SklearnClassifier(pipeline).train(data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uGuZKN3cPGzP"
      },
      "source": [
        "# Question 3: Cross-validation (20 marks)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "er239vJsPGzQ"
      },
      "outputs": [],
      "source": [
        "#solution\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "\n",
        "\n",
        "def cross_validate(dataset, folds):\n",
        "    results=[]\n",
        "    cv_results = []\n",
        "    accuracy = []\n",
        "    fold_size = int(len(dataset)/folds) + 1\n",
        "    for i in range(0,len(dataset),int(fold_size)):\n",
        "        # insert code here that trains and tests on the 10 folds of data in the dataset\n",
        "        print(\"Fold start on items %d - %d\" % (i, i+fold_size))\n",
        "        # FILL IN THE METHOD HERE\n",
        "        train_set = dataset[:i] + dataset[i+fold_size:]\n",
        "        valid_set = dataset[i:i+fold_size]\n",
        "        samples, labels = map(list, zip(*valid_set))\n",
        "        classifier = train_classifier(train_set)\n",
        "        #y_predict\n",
        "        predictions = predict_labels(samples, classifier)\n",
        "        results += predictions\n",
        "        #y_true = label \n",
        "        y_true = [x[1] for x in valid_set]\n",
        "        cv_results.append(precision_recall_fscore_support(y_true, predictions, average='weighted'))\n",
        "        accuracy.append(accuracy_score(y_true, predictions))\n",
        "\n",
        "    train_set_label = [sample[1] for sample in dataset]    \n",
        "    print(classification_report(train_set_label, results))    \n",
        "# Average calculation of values oer 10 fold runs\n",
        "    cv_results = np.array(cv_results)\n",
        "    cv_results = [np.mean(cv_results[:,0]), np.mean(cv_results[:,1]), np.mean(cv_results[:,2])]\n",
        "\n",
        "    accuracy = np.asarray(accuracy)\n",
        "    accuracy = np.mean(accuracy)\n",
        "\n",
        "    print('The overall precision is {}'\n",
        "          '\\nrecall score is {}'\n",
        "          '\\nf1 score is {}'\n",
        "          '\\naccuracy is {}'.format(cv_results[0],cv_results[1],cv_results[2],accuracy))\n",
        "\n",
        "    predicted_label_data = []\n",
        "    for i in range(len(dataset)):\n",
        "        list_dataset = list(dataset[i])\n",
        "        list_dataset = list_dataset + [results[i]]\n",
        "        predicted_label_data.append(list_dataset)\n",
        "\n",
        "    return cv_results, predicted_label_data\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "C-lWb_n8PGzQ"
      },
      "outputs": [],
      "source": [
        "# PREDICTING LABELS GIVEN A CLASSIFIER\n",
        "\n",
        "def predict_labels(samples, classifier):\n",
        "    \"\"\"Assuming preprocessed samples, return their predicted labels from the classifier model.\"\"\"\n",
        "    return classifier.classify_many(samples)\n",
        "\n",
        "def predict_label_from_raw(sample, classifier):\n",
        "    \"\"\"Assuming raw text, return its predicted label from the classifier model.\"\"\"\n",
        "    return classifier.classify(to_feature_vector(preProcess(reviewSample)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zM8UMo6bPGzQ",
        "outputId": "3387b944-03b4-4f0c-a6b2-caf605667b57"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Now 0 rawData, 0 trainData, 0 testData\n",
            "Preparing the dataset...\n",
            "Now 10241 rawData, 0 trainData, 0 testData\n",
            "Preparing training and test data...\n",
            "After split, 10241 rawData, 8192 trainData, 2049 testData\n",
            "Training Samples: \n",
            "8192\n",
            "Features: \n",
            "84109\n"
          ]
        }
      ],
      "source": [
        "# MAIN\n",
        "\n",
        "# loading reviews\n",
        "# initialize global lists that will be appended to by the methods below\n",
        "raw_data = []          # the filtered data from the dataset file\n",
        "train_data = []        # the pre-processed training data as a percentage of the total dataset\n",
        "test_data = []         # the pre-processed test data as a percentage of the total dataset\n",
        "\n",
        "\n",
        "# references to the data files\n",
        "data_file_path = 'fake_news.tsv'\n",
        "\n",
        "# Do the actual stuff (i.e. call the functions we've made)\n",
        "# We parse the dataset and put it in a raw data list\n",
        "print(\"Now %d rawData, %d trainData, %d testData\" % (len(raw_data), len(train_data), len(test_data)),\n",
        "      \"Preparing the dataset...\",sep='\\n')\n",
        "\n",
        "load_data(data_file_path) \n",
        "\n",
        "# We split the raw dataset into a set of training data and a set of test data (80/20)\n",
        "# You do the cross validation on the 80% (training data)\n",
        "# We print the number of training samples and the number of features before the split\n",
        "print(\"Now %d rawData, %d trainData, %d testData\" % (len(raw_data), len(train_data), len(test_data)),\n",
        "      \"Preparing training and test data...\",sep='\\n')\n",
        "\n",
        "\n",
        "split_and_preprocess_data(0.8)\n",
        "\n",
        "# We print the number of training samples and the number of features after the split\n",
        "print(\"After split, %d rawData, %d trainData, %d testData\" % (len(raw_data), len(train_data), len(test_data)),\n",
        "      \"Training Samples: \", len(train_data), \"Features: \", len(global_feature_dict), sep='\\n')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "jsujEFgiZWB6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4d0bd3ee-4ca9-4b90-e85b-bc1f7c9b372c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold start on items 0 - 820\n",
            "Training Classifier...\n",
            "Fold start on items 820 - 1640\n",
            "Training Classifier...\n",
            "Fold start on items 1640 - 2460\n",
            "Training Classifier...\n",
            "Fold start on items 2460 - 3280\n",
            "Training Classifier...\n",
            "Fold start on items 3280 - 4100\n",
            "Training Classifier...\n",
            "Fold start on items 4100 - 4920\n",
            "Training Classifier...\n",
            "Fold start on items 4920 - 5740\n",
            "Training Classifier...\n",
            "Fold start on items 5740 - 6560\n",
            "Training Classifier...\n",
            "Fold start on items 6560 - 7380\n",
            "Training Classifier...\n",
            "Fold start on items 7380 - 8200\n",
            "Training Classifier...\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        FAKE       0.51      0.48      0.49      3562\n",
            "        REAL       0.62      0.65      0.63      4630\n",
            "\n",
            "    accuracy                           0.57      8192\n",
            "   macro avg       0.56      0.56      0.56      8192\n",
            "weighted avg       0.57      0.57      0.57      8192\n",
            "\n",
            "The overall precision is 0.5726008664300004\n",
            "recall score is 0.5748582241980055\n",
            "f1 score is 0.5728748238267123\n",
            "accuracy is 0.5748582241980055\n"
          ]
        }
      ],
      "source": [
        "cv_results, predicted_label_data = cross_validate(train_data, 10)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}