{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sMGQXyMzPGzK",
        "outputId": "c9a4cfb3-4a2a-454f-b3ed-7a7f075330d0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (3.7)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.7/dist-packages (from nltk) (2022.6.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from nltk) (4.64.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from nltk) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from nltk) (1.2.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install nltk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "nOBr4d31PGzM"
      },
      "outputs": [],
      "source": [
        "import csv                               # csv reader\n",
        "from sklearn.svm import LinearSVC\n",
        "from nltk.classify import SklearnClassifier\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import precision_recall_fscore_support # to report on precision and recall\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "qoPdohdUPGzM"
      },
      "outputs": [],
      "source": [
        "def load_data(path):\n",
        "    \"\"\"Load data from a tab-separated file and append it to raw_data.\"\"\"\n",
        "    with open(path) as f:\n",
        "        reader = csv.reader(f, delimiter='\\t')\n",
        "        for line in reader:\n",
        "            if line[0] == \"Id\":  # skip header\n",
        "                continue\n",
        "            (label, text, total_barely_true_counts, total_false_counts, total_half_true_counts, total_mostly_true_counts) = parse_data_line(line)\n",
        "            raw_data.append((text, label, total_barely_true_counts, total_false_counts, total_half_true_counts, total_mostly_true_counts))\n",
        "\n",
        "\n",
        "def split_and_preprocess_data(percentage):\n",
        "    \"\"\"Split the data between train_data and test_data according to the percentage\n",
        "    and performs the preprocessing.\"\"\"\n",
        "    num_samples = len(raw_data)\n",
        "    num_training_samples = int((percentage * num_samples))\n",
        "    for (text, label, total_barely_true_counts, total_false_counts, total_half_true_counts, total_mostly_true_counts) in raw_data[:num_training_samples]:\n",
        "        # Update the dictionary\n",
        "        dictionary = (to_feature_vector(pre_process(text)))\n",
        "        dictionary['total_barely_true_counts'] = total_barely_true_counts\n",
        "        dictionary['total_false_counts'] = total_false_counts\n",
        "        dictionary['total_half_true_counts'] = total_half_true_counts\n",
        "        dictionary['total_mostly_true_counts'] = total_mostly_true_counts\n",
        "        train_data.append((dictionary,label))\n",
        "    for (text, label, total_barely_true_counts, total_false_counts, total_half_true_counts, total_mostly_true_counts) in raw_data[num_training_samples:]:\n",
        "        dictionary = (to_feature_vector(pre_process(text)))\n",
        "        dictionary['total_barely_true_counts'] = total_barely_true_counts\n",
        "        dictionary['total_false_counts'] = total_false_counts\n",
        "        dictionary['total_half_true_counts'] = total_half_true_counts\n",
        "        dictionary['total_mostly_true_counts'] = total_mostly_true_counts\n",
        "        test_data.append((dictionary,label))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d7yeUVmVPGzN"
      },
      "source": [
        "# Question 1: Input and Basic preprocessing (10 marks)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "j4UQuRFyPGzN"
      },
      "outputs": [],
      "source": [
        "def convert_label(label):\n",
        "    \"\"\"Converts the multiple classes into two,\n",
        "    making it a binary distinction between fake news and real.\"\"\"\n",
        "    #return label\n",
        "    # Converting the multiclass labels to binary label\n",
        "    labels_map = {\n",
        "        'true': 'REAL',\n",
        "        'mostly-true': 'REAL',\n",
        "        'half-true': 'REAL',\n",
        "        'false': 'FAKE',\n",
        "        'barely-true': 'FAKE',\n",
        "        'pants-fire': 'FAKE'\n",
        "    }\n",
        "    return labels_map[label]\n",
        "\n",
        "\n",
        "def parse_data_line(data_line):\n",
        "    # Should return a tuple of the label as just FAKE or REAL and the statement\n",
        "    label = convert_label(data_line[1])\n",
        "    statement = data_line[2]\n",
        "    total_barely_true_counts = data_line[8]\n",
        "    total_false_counts = data_line[9]\n",
        "    total_half_true_counts = data_line[10]\n",
        "    total_mostly_true_counts = data_line[11]\n",
        "    return (label, statement, total_barely_true_counts, total_false_counts, total_half_true_counts, total_mostly_true_counts)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F2LNz4oePGzO",
        "outputId": "8b662c4d-272d-48b1-e66a-e59cae45d88b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "from string import punctuation\n",
        "import nltk\n",
        "import re\n",
        "nltk.download('punkt')\n",
        "\n",
        "# Input: a string of one statement\n",
        "def pre_process(text):\n",
        "    # Should return a list of tokens\n",
        "    # DESCRIBE YOUR METHOD IN WORDS\n",
        "    text = re.sub(r\"(\\w)([.,;:!?'\\\"”\\)])\", r\"\\1 \\2\", text) # separate punctuation at ends of\n",
        "    text = re.sub(r\"([.,;:!?'\\\"“\\(\\)])(\\w)\", r\"\\1 \\2\", text)  # separate punctuation at beginning of words\n",
        "    text = re.split(r\"\\s+\",text) # divide strings into words \n",
        "    tokens = [t.lower() for t in text] # lower case\n",
        "    return tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "kXtj4A7raPeS"
      },
      "outputs": [],
      "source": [
        "#[word.lower() for word in word_tokenize(text) if word not in punctuation]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XpaTPyLzPGzO"
      },
      "source": [
        "# Question 2: Basic Feature Extraction (20 marks)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "fiI-bQxHPGzP"
      },
      "outputs": [],
      "source": [
        "global_feature_dict = {} # A global dictionary of features\n",
        "\n",
        "def to_feature_vector(tokens):\n",
        "    # Should return a dictionary containing features as keys, and weights as values\n",
        "    # DESCRIBE YOUR METHOD IN WORDS\n",
        "    result = {}\n",
        "    for token in tokens:\n",
        "        if token not in result:\n",
        "            result[token] = 0\n",
        "        result[token] += 1\n",
        "        if token not in global_feature_dict:\n",
        "            global_feature_dict[token] = 0\n",
        "        global_feature_dict[token] += 1\n",
        "    return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "Pjq9MqvXPGzP"
      },
      "outputs": [],
      "source": [
        "# TRAINING AND VALIDATING OUR CLASSIFIER\n",
        "\n",
        "def train_classifier(data):\n",
        "    print(\"Training Classifier...\")\n",
        "    pipeline =  Pipeline([('svc', LinearSVC())])\n",
        "    return SklearnClassifier(pipeline).train(data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uGuZKN3cPGzP"
      },
      "source": [
        "# Question 3: Cross-validation (20 marks)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "er239vJsPGzQ"
      },
      "outputs": [],
      "source": [
        "#solution\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "\n",
        "\n",
        "def cross_validate(dataset, folds):\n",
        "    results=[]\n",
        "    cv_results = []\n",
        "    accuracy = []\n",
        "    fold_size = int(len(dataset)/folds) + 1\n",
        "    for i in range(0,len(dataset),int(fold_size)):\n",
        "        # insert code here that trains and tests on the 10 folds of data in the dataset\n",
        "        print(\"Fold start on items %d - %d\" % (i, i+fold_size))\n",
        "        # FILL IN THE METHOD HERE\n",
        "        train_set = dataset[:i] + dataset[i+fold_size:]\n",
        "        valid_set = dataset[i:i+fold_size]\n",
        "        samples, labels = map(list, zip(*valid_set))\n",
        "        classifier = train_classifier(train_set)\n",
        "        #y_predict\n",
        "        predictions = predict_labels(samples, classifier)\n",
        "        results += predictions\n",
        "        #y_true = label \n",
        "        y_true = [x[1] for x in valid_set]\n",
        "        cv_results.append(precision_recall_fscore_support(y_true, predictions, average='weighted'))\n",
        "        accuracy.append(accuracy_score(y_true, predictions))\n",
        "\n",
        "    train_set_label = [sample[1] for sample in dataset]    \n",
        "    print(classification_report(train_set_label, results))    \n",
        "# Average calculation of values oer 10 fold runs\n",
        "    cv_results = np.array(cv_results)\n",
        "    cv_results = [np.mean(cv_results[:,0]), np.mean(cv_results[:,1]), np.mean(cv_results[:,2])]\n",
        "\n",
        "    accuracy = np.asarray(accuracy)\n",
        "    accuracy = np.mean(accuracy)\n",
        "\n",
        "    print('The overall precision is {}'\n",
        "          '\\nrecall score is {}'\n",
        "          '\\nf1 score is {}'\n",
        "          '\\naccuracy is {}'.format(cv_results[0],cv_results[1],cv_results[2],accuracy))\n",
        "\n",
        "    predicted_label_data= []\n",
        "    for i in range(len(dataset)):\n",
        "        list_dataset = list(dataset[i])\n",
        "        list_dataset = list_dataset + [results[i]]\n",
        "        predicted_label_data.append(list_dataset)\n",
        "\n",
        "    return cv_results, predicted_label_data\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "C-lWb_n8PGzQ"
      },
      "outputs": [],
      "source": [
        "# PREDICTING LABELS GIVEN A CLASSIFIER\n",
        "\n",
        "def predict_labels(samples, classifier):\n",
        "    \"\"\"Assuming preprocessed samples, return their predicted labels from the classifier model.\"\"\"\n",
        "    return classifier.classify_many(samples)\n",
        "\n",
        "def predict_label_from_raw(sample, classifier):\n",
        "    \"\"\"Assuming raw text, return its predicted label from the classifier model.\"\"\"\n",
        "    return classifier.classify(to_feature_vector(preProcess(reviewSample)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zM8UMo6bPGzQ",
        "outputId": "cd0713dc-7c85-43e0-d325-7722515dec5e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Now 0 rawData, 0 trainData, 0 testData\n",
            "Preparing the dataset...\n",
            "Now 10241 rawData, 0 trainData, 0 testData\n",
            "Preparing training and test data...\n",
            "After split, 10241 rawData, 8192 trainData, 2049 testData\n",
            "Training Samples: \n",
            "8192\n",
            "Features: \n",
            "13560\n"
          ]
        }
      ],
      "source": [
        "# MAIN\n",
        "\n",
        "# loading reviews\n",
        "# initialize global lists that will be appended to by the methods below\n",
        "raw_data = []          # the filtered data from the dataset file\n",
        "train_data = []        # the pre-processed training data as a percentage of the total dataset\n",
        "test_data = []         # the pre-processed test data as a percentage of the total dataset\n",
        "\n",
        "\n",
        "# references to the data files\n",
        "data_file_path = 'fake_news.tsv'\n",
        "\n",
        "# Do the actual stuff (i.e. call the functions we've made)\n",
        "# We parse the dataset and put it in a raw data list\n",
        "print(\"Now %d rawData, %d trainData, %d testData\" % (len(raw_data), len(train_data), len(test_data)),\n",
        "      \"Preparing the dataset...\",sep='\\n')\n",
        "\n",
        "load_data(data_file_path) \n",
        "\n",
        "# We split the raw dataset into a set of training data and a set of test data (80/20)\n",
        "# You do the cross validation on the 80% (training data)\n",
        "# We print the number of training samples and the number of features before the split\n",
        "print(\"Now %d rawData, %d trainData, %d testData\" % (len(raw_data), len(train_data), len(test_data)),\n",
        "      \"Preparing training and test data...\",sep='\\n')\n",
        "\n",
        "\n",
        "split_and_preprocess_data(0.8)\n",
        "\n",
        "# We print the number of training samples and the number of features after the split\n",
        "print(\"After split, %d rawData, %d trainData, %d testData\" % (len(raw_data), len(train_data), len(test_data)),\n",
        "      \"Training Samples: \", len(train_data), \"Features: \", len(global_feature_dict), sep='\\n')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jsujEFgiZWB6",
        "outputId": "9d7eb73e-a90d-4d5c-a0b8-8d73c343b2b7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold start on items 0 - 820\n",
            "Training Classifier...\n",
            "Fold start on items 820 - 1640\n",
            "Training Classifier...\n",
            "Fold start on items 1640 - 2460\n",
            "Training Classifier...\n",
            "Fold start on items 2460 - 3280\n",
            "Training Classifier...\n",
            "Fold start on items 3280 - 4100\n",
            "Training Classifier...\n",
            "Fold start on items 4100 - 4920\n",
            "Training Classifier...\n",
            "Fold start on items 4920 - 5740\n",
            "Training Classifier...\n",
            "Fold start on items 5740 - 6560\n",
            "Training Classifier...\n",
            "Fold start on items 6560 - 7380\n",
            "Training Classifier...\n",
            "Fold start on items 7380 - 8200\n",
            "Training Classifier...\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        FAKE       0.60      0.60      0.60      3562\n",
            "        REAL       0.69      0.69      0.69      4630\n",
            "\n",
            "    accuracy                           0.65      8192\n",
            "   macro avg       0.64      0.64      0.64      8192\n",
            "weighted avg       0.65      0.65      0.65      8192\n",
            "\n",
            "The overall precision is 0.6515008382044486\n",
            "recall score is 0.6506584164363811\n",
            "f1 score is 0.6507457214640542\n",
            "accuracy is 0.6506584164363811\n"
          ]
        }
      ],
      "source": [
        "cv_results, predicted_label_data = cross_validate(train_data, 10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GQXi_7FLPGzR"
      },
      "source": [
        "# 4. Error Analysis (10 marks)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "GaJ25h2KQUyN"
      },
      "outputs": [],
      "source": [
        "def crossValidate(dataset, folds):\n",
        "    cv_results = []\n",
        "    accuracy = []\n",
        "    shuffle(dataset)\n",
        "    foldSize = int(len(dataset)/folds)\n",
        "    for i in range(0,len(dataset),foldSize):\n",
        "        # insert code here that trains and tests on the 10 folds of data in the dataset\n",
        "        print (\"fold start %d foldSize %d\" % (i, foldSize))\n",
        "        myTestData = dataset[i:i+foldSize]\n",
        "        myTrainData = dataset[0:i] + dataset[i+foldSize:]\n",
        "        classifier = trainClassifier(myTrainData)\n",
        "        y_pred = predictLabels(myTestData, classifier)\n",
        "#         review,label = zip(*myTestData)\n",
        "#         y_true = label\n",
        "        y_true = [x[1] for x in myTestData]\n",
        "#         y_true = classifier.classify(map(lambda x: x[1], myTestData))\n",
        "        cv_results.append(precision_recall_fscore_support(y_true, y_pred, average='weighted'))\n",
        "        accuracy.append(accuracy_score(y_true, y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "gsVmLzcJPGzR"
      },
      "outputs": [],
      "source": [
        "from sklearn import metrics\n",
        "import matplotlib.pyplot as plt\n",
        "# a function to make the confusion matrix readable and pretty\n",
        "def confusion_matrix_heatmap(y_test, preds, labels):\n",
        "    \"\"\"Function to plot a confusion matrix\"\"\"\n",
        "    # pass labels to the confusion matrix function to ensure right order\n",
        "    cm = metrics.confusion_matrix(y_test, preds, labels=labels)\n",
        "    fig = plt.figure(figsize=(10,10))\n",
        "    ax = fig.add_subplot(111)\n",
        "    cax = ax.matshow(cm)\n",
        "    plt.title('Confusion matrix of the classifier')\n",
        "    fig.colorbar(cax)\n",
        "    ax.set_xticks(np.arange(len(labels)))\n",
        "    ax.set_yticks(np.arange(len(labels)))\n",
        "    ax.set_xticklabels( labels, rotation=45)\n",
        "    ax.set_yticklabels( labels)\n",
        "\n",
        "    for i in range(len(cm)):\n",
        "        for j in range(len(cm)):\n",
        "            text = ax.text(j, i, cm[i, j],\n",
        "                           ha=\"center\", va=\"center\", color=\"w\")\n",
        "\n",
        "    plt.xlabel('Predicted')\n",
        "    plt.ylabel('True')\n",
        "    \n",
        "    # fix for mpl bug that cuts off top/bottom of seaborn viz:\n",
        "    b, t = plt.ylim() # discover the values for bottom and top\n",
        "    b += 0.5 # Add 0.5 to the bottom\n",
        "    t -= 0.5 # Subtract 0.5 from the top\n",
        "    plt.ylim(b, t) # update the ylim(bottom, top) values\n",
        "    plt.show() # ta-da!\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 632
        },
        "id": "h3VSoeRf5LCe",
        "outputId": "99ccc230-b80e-4ab9-f64b-d82e058e6393"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x720 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "labels = ['REAL', 'FAKE']\n",
        "train_data_label = [sample[1] for sample in predicted_label_data[:820]]\n",
        "train_predict_label = [sample[2] for sample in predicted_label_data[:820]]\n",
        "confusion_matrix_heatmap(train_data_label, train_predict_label, labels)\n",
        "\n",
        "false_positive = []\n",
        "false_negative = []\n",
        "for i in range(len(train_data_label)):\n",
        "    if predicted_label_data[i][1] == 'FAKE' and predicted_label_data[i][2] == 'REAL':\n",
        "        false_negative.append(predicted_label_data[i])\n",
        "    if predicted_label_data[i][1] == 'REAL' and predicted_label_data[i][2] == 'FAKE':\n",
        "        false_positive.append(predicted_label_data[i])\n",
        "\n",
        "def file_print_out(false):\n",
        "    raw_data_spilt = [pre_process(text[0]) for text in raw_data]\n",
        "    false_list = [list(text[0]) for text in false]\n",
        "    output_list = []\n",
        "    for tokens_1 in false_list:\n",
        "      for i in range(len(raw_data_spilt)):\n",
        "        if all(list(word in raw_data_spilt[i] for word in tokens_1)):\n",
        "            output_list.append(raw_data[i])\n",
        "    print(output_list)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0xvjFpYJAwox",
        "outputId": "66e793ed-0e5c-4172-d500-39b0a549a5dc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "({'the': 2, 'bush': 1, 'tax': 1, 'cuts': 1, 'helped': 1, 'to': 1, 'create': 1, 'a': 1, 'substantial': 1, 'part': 1, 'of': 1, 'deficit': 1, '.': 1, 'total_barely_true_counts': '1', 'total_false_counts': '3', 'total_half_true_counts': '4', 'total_mostly_true_counts': '6'}, 'REAL')\n",
            "8192\n",
            "Training Classifier...\n",
            "Done training!\n",
            "Precision: 0.644901\n",
            "Recall: 0.645193\n",
            "F Score:0.645034\n",
            "Accuracy:0.645193\n"
          ]
        }
      ],
      "source": [
        "# Finally, check the accuracy of your classifier by training on all the traning data\n",
        "# and testing on the test set\n",
        "# Will only work once all functions are complete\n",
        "functions_complete = True  # set to True once you're happy with your methods for cross val\n",
        "if functions_complete:\n",
        "    print(test_data[0])   # have a look at the first test data instance\n",
        "    print(len(train_data))\n",
        "    classifier = train_classifier(train_data)  # train the classifier\n",
        "    test_true = [t[1] for t in test_data]   # get the ground-truth labels from the data\n",
        "    test_pred = predict_labels([x[0] for x in test_data], classifier)  # classify the test data to get predicted labels\n",
        "    final_scores = precision_recall_fscore_support(test_true, test_pred, average='weighted') # evaluate\n",
        "    accuracy = np.mean(np.array(accuracy_score(test_true, test_pred)))\n",
        "    print(\"Done training!\")\n",
        "    print(\"Precision: %f\\nRecall: %f\\nF Score:%f\" % final_scores[:3])\n",
        "    print(\"Accuracy:%f\" % accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "Yr4a5ubHBYwV"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}